{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset \n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df = pd.read_excel('data.xlsx')\n",
    "df = pd.read_excel('diabetes_multi.xlsx', sheet_name=1)# Extract one certain sheet in excel\n",
    "df = pd.read_json(\"diabetes.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104be93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy, avoid changing the original dataset \n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole picture of the dataset\n",
    "df.shape \n",
    "df.describe()\n",
    "\n",
    "df.columns\n",
    "df2.isnull().sum() # see number of nulls in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ef073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names to the values of the first row\n",
    "df_health.columns = df_health.iloc[0]\n",
    "df_health = df_health[1:]  # Remove the first row\n",
    "df_health.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea477e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate part of the dataset\n",
    "\n",
    "# column\n",
    "df['Outcome']     # one column\n",
    "df[['colu1', 'colu2']]    # two or more columns\n",
    "\n",
    "# row\n",
    "# Using .loc[] and .iloc[] to fetch rows\n",
    "# .loc[] uses a label to point to a row, column or cell, whereas .iloc[] uses the numeric position\n",
    "# The 1 represents the row index (label), whereas the 1 in .iloc[] is the row position (first row).\n",
    "df2.loc[1]   # the row with the index 1\n",
    "df2.iloc[1]  # first row in the datframe\n",
    "\n",
    "\n",
    "\n",
    "# You can also select specific columns along with rows. \n",
    "# This is where .iloc[] is different from .loc[] – it requires column location and not column labels.\n",
    "\n",
    "df2.loc[100:110, ['Pregnancies', 'Glucose', 'BloodPressure']]\n",
    "df2.iloc[100:110, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional slicing\n",
    "df[df.BloodPressure == 122]\n",
    "df.loc[df['BloodPressure'] > 100, ['Pregnancies', 'Glucose', 'BloodPressure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b193e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# drop the rows with missing values \n",
    "df_new = df3.dropna()  # save the changed dataset into df_new, df3 remains the same\n",
    "df3.dropna(inplace=True） # change df3 directly\n",
    "df_states = df_states.dropna(subset=['Population'])\n",
    "df_states =df_states.drop('Level',axis=1) # drop column\n",
    "\n",
    "# fill missing values\n",
    "# Get the mean of certain row\n",
    "mean_value = df3['Pregnancies'].mean()\n",
    "df_new=df3['Pregnancies'].fillna(mean_value)\n",
    "           \n",
    "# Dealing with Duplicate Data\n",
    "df3 = df3.drop_duplicates()  # drop rows that are the same\n",
    "\n",
    "# rename columns\n",
    "df3.rename(columns = {'DiabetesPedigreeFunction':'DPF'}, inplace = True)\n",
    "df3.columns = ['Glucose','Age', 'Outcome', 'STF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column\n",
    "df2['Glucose_Insulin_Ratio'] = df2['Glucose']/df2['Insulin']\n",
    "\n",
    "# count category values\n",
    "df['Outcome'].value_counts()\n",
    "df['Outcome'].value_counts(normalize=True) # return proportions\n",
    "\n",
    "# aggregation, groupby\n",
    "df.groupby('Outcome').mean()\n",
    "# get certain group\n",
    "df_pop=df_pop.groupby(\"Rural/Urban\")\n",
    "df_pop_total=df_pop.get_group(\"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf482ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging datasets \n",
    "df_combine  = pd.merge(df_mile,df_country,on='Countries', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ea665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caitalize/lowercase strings \n",
    "df_pop[\"Name\"] = df_pop[\"Name\"].str.capitalize()\n",
    "df_medicine[\"State_NN\"] = df_medicine[\"State_NN\"].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values based on certain column\n",
    "df_states_sorted_asc = df_states.sort_values(by='Diabetes_pop', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81abacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and output data\n",
    "df.to_csv('output.csv', index=False)  # do not save index\n",
    "df.to_excel(\"diabetes_out.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
